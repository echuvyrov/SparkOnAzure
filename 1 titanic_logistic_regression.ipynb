{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Preliminaries\n",
    "Add the necessary libraries and create Spark Context and create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "\n",
    "sc = SparkContext(appName=\"TitanicLR\")\n",
    "#open file from Azure Storage\n",
    "fileNameTrain = 'wasb://kaggle@criteo.blob.core.windows.net/train.csv'\n",
    "\n",
    "#create RDD\n",
    "points = sc.textFile(fileNameTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to parse CSV lines and convert them to LabeledPoint. LabeledPoint is the class that our Machine Learning algorithms expects (down below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    \"\"\"\n",
    "    Parse a line of text into an MLlib LabeledPoint object.\n",
    "    \"\"\"\n",
    "    values = line.split(',')\n",
    "    values = [0 if e == '' else e for e in values]\n",
    "    return LabeledPoint(float(values[1]), [float(values[2]),float(values[6]),float(values[7]),float(values[8]),float(values[10])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the header information - there are certainly other (more efficient) ways to do it but this also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n"
     ]
    }
   ],
   "source": [
    "#skip header\n",
    "header = points.first() #extract header\n",
    "points = points.filter(lambda x:x !=header) #filter out header\n",
    "\n",
    "print points.first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply transformation on every line of the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeledPoints = points.map(parsePoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MLLib Logistic Regression on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights: [-3.18506726732,-0.729241975158,-1.71365575134,-0.384488786453,0.403867774938]\n",
      "Final intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegressionWithSGD.train(labeledPoints)\n",
    "print(\"Final weights: \" + str(model.weights))\n",
    "print(\"Final intercept: \" + str(model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform basic evaluation of the model - % correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.334455667789\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "labelsAndPreds = labeledPoints.map(lambda point: (int(point.label),\n",
    "        model.predict(point.features)))\n",
    "\n",
    "# Evaluating the model on training data\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(labeledPoints.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now prepare the testing data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q', u'893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "def parseTestPoint(line):\n",
    "    \"\"\"\n",
    "    Parse a line of text into an MLlib LabeledPoint object.\n",
    "    \"\"\"\n",
    "    values = line.split(',')\n",
    "    values = [0 if e == '' else e for e in values]\n",
    "    return Vectors.dense([float(values[1]),float(values[5]),float(values[6]),float(values[7]),float(values[9])])\n",
    "\n",
    "fileNameTest = 'wasb://kaggle@criteo.blob.core.windows.net/test.csv'\n",
    "testPoints = sc.textFile(fileNameTest)\n",
    "\n",
    "#skip header\n",
    "headerTest = testPoints.first() #extract header\n",
    "testPoints = testPoints.filter(lambda x:x !=headerTest) #filter out header\n",
    "print testPoints.take(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "testPoints = testPoints.map(parseTestPoint)\n",
    "\n",
    "predictions = model.predict(testPoints)\n",
    "print predictions.take(125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare .CSV for submission - grab Ids from the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'892', u'893', u'894']\n"
     ]
    }
   ],
   "source": [
    "#write out predictions to .CSV file\n",
    "submissionIds = sc.textFile(fileNameTest).map(lambda x: x.split(',')[0])\n",
    "\n",
    "#skip header\n",
    "headerSubmission = submissionIds.first() #extract header\n",
    "submissionIds = submissionIds.filter(lambda x:x !=headerSubmission) #filter out header\n",
    "print submissionIds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Ids with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = submissionIds.zip(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write out the CSV file to Azure storage. Notice the coalesce(1,True) to force the job to execute on a single node (and thus, create a single file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.map(lambda a: str(a[0]) + \",\" + str(a[1])).coalesce(1,True).saveAsTextFile('wasb://criteo@criteo.blob.core.windows.net/kaggle/svcc_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
